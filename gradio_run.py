"""
Gradio åº”ç”¨ - çŒ«ç‹—åˆ†ç±»

æä¾›åŸºäº Web çš„å›¾åƒåˆ†ç±»æ¨ç†ç•Œé¢ï¼Œæ”¯æŒå•å¼ å›¾ç‰‡ä¸Šä¼ å’Œå®æ—¶é¢„æµ‹ã€‚
"""

import argparse
from pathlib import Path

import torch
import torch.nn.functional as F
from PIL import Image

import gradio as gr

from src.utils.inference_utils import prepare_model, CLASS_NAMES
from src.data.data_utils import build_transforms


class CatDogClassifier:
    """çŒ«ç‹—åˆ†ç±»å™¨å°è£…ç±»ï¼Œç”¨äº Gradio åº”ç”¨ã€‚"""
    
    def __init__(self, checkpoint_path=None, device=None, arch=None):
        """åˆå§‹åŒ–åˆ†ç±»å™¨ã€‚
        
        å‚æ•°:
            checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸º None åˆ™å»¶è¿ŸåŠ è½½ï¼‰ã€‚
            device: æ¨ç†è®¾å¤‡ï¼ˆstrï¼Œå¯é€‰ï¼‰ï¼Œé»˜è®¤è‡ªåŠ¨é€‰æ‹©ã€‚
            arch: æ¨¡å‹æ¶æ„åç§°ï¼ˆstrï¼Œå¯é€‰ï¼‰ï¼Œç”¨äºè¦†ç›–æ£€æŸ¥ç‚¹é…ç½®ã€‚
        """
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        self.arch = arch
        self.model = None
        self.config = None
        self.checkpoint_path = None
        self.image_size = 224
        self.normalize_imagenet = False
        self.transform = None
        self.class_names = CLASS_NAMES
        
        if checkpoint_path is not None:
            self.load_model(checkpoint_path)
    
    def load_model(self, checkpoint_path):
        """åŠ è½½æˆ–é‡æ–°åŠ è½½æ¨¡å‹ã€‚
        
        å‚æ•°:
            checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ã€‚
        """
        self.checkpoint_path = checkpoint_path
        self.model, self.config = prepare_model(checkpoint_path, device=self.device, arch=self.arch)
        
        # ä»é…ç½®ä¸­è¯»å–æ¨ç†å‚æ•°
        self.image_size = self.config.get("image_size", 224)
        self.normalize_imagenet = self.config.get("normalize_imagenet", False)
        
        # æ„å»ºå›¾åƒå˜æ¢
        self.transform = build_transforms(
            size=self.image_size,
            augment=False,
            use_imagenet_norm=self.normalize_imagenet,
        )
    
    def predict(self, image, threshold=0.5):
        """å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œé¢„æµ‹ã€‚
        
        å‚æ•°:
            image: PIL.Image å¯¹è±¡æˆ– numpy æ•°ç»„ã€‚
            threshold: åˆ¤æ–­ä¸ºç‹—çš„æ¦‚ç‡é˜ˆå€¼ï¼ˆfloatï¼Œé»˜è®¤: 0.5ï¼‰ã€‚
            
        è¿”å›:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸ï¼ŒåŒ…å« labelã€label_nameã€probã€prob_dogã€prob_catã€‚
        """
        if image is None:
            return None
        
        if self.model is None or self.transform is None:
            return {"error": "æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆé€‰æ‹©æ¨¡å‹"}
        
        # ç¡®ä¿æ˜¯ PIL Image
        if not isinstance(image, Image.Image):
            image = Image.fromarray(image)
        
        # è½¬æ¢ä¸º RGB
        image = image.convert("RGB")
        
        # é¢„å¤„ç†
        tensor = self.transform(image)  # è¿”å› torch.Tensor
        tensor = tensor.unsqueeze(0)  # æ·»åŠ  batch ç»´åº¦
        tensor = tensor.to(self.device)
        
        # æ¨ç†
        self.model.eval()
        with torch.no_grad():
            logits = self.model(tensor)
            prob_dog = torch.sigmoid(logits.view(-1)).item()
        
        prob_cat = 1.0 - prob_dog
        label = 1 if prob_dog >= threshold else 0
        label_name = self.class_names[label]
        
        return {
            "label": label,
            "label_name": label_name,
            "prob": prob_dog,
            "prob_dog": prob_dog,
            "prob_cat": prob_cat,
        }
    
    def predict_with_display(self, image, threshold=0.5):
        """é¢„æµ‹å¹¶æ ¼å¼åŒ–æ˜¾ç¤ºç»“æœã€‚
        
        å‚æ•°:
            image: PIL.Image å¯¹è±¡æˆ– numpy æ•°ç»„ã€‚
            threshold: åˆ¤æ–­ä¸ºç‹—çš„æ¦‚ç‡é˜ˆå€¼ï¼ˆfloatï¼Œé»˜è®¤: 0.5ï¼‰ã€‚
            
        è¿”å›:
            tuple: (æ˜¾ç¤ºæ–‡æœ¬, ç±»åˆ«åç§°, ç½®ä¿¡åº¦å­—å…¸, æ¨¡å‹ä¿¡æ¯)
        """
        result = self.predict(image, threshold)
        if result is None:
            return "âŒ è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡", None, None, None
        
        if "error" in result:
            return "âŒ {}".format(result["error"]), None, None, None
        
        label_name = result["label_name"]
        prob_dog = result["prob_dog"]
        prob_cat = result["prob_cat"]
        
        # é€‰æ‹© emoji
        emoji = "ğŸ±" if label_name == "cats" else "ğŸ¶"
        
        # æ¨¡å‹ä¿¡æ¯
        model_info = ""
        if self.checkpoint_path:
            model_name = Path(self.checkpoint_path).name
            model_info = f"**å½“å‰æ¨¡å‹:** `{model_name}`\n"
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºæ–‡æœ¬
        display_text = f"""
{emoji} **é¢„æµ‹ç»“æœ: {label_name.upper()}**

{model_info}ğŸ“Š **ç½®ä¿¡åº¦:**
- ğŸ± çŒ«: {prob_cat:.2%}
- ğŸ¶ ç‹—: {prob_dog:.2%}

ğŸ¯ **é˜ˆå€¼:** {threshold:.2f}
"""
        
        # ç½®ä¿¡åº¦å­—å…¸ç”¨äºå¯è§†åŒ–ï¼ˆLabel ç»„ä»¶æ ¼å¼ï¼‰
        confidence_dict = {
            "cats": float(prob_cat),
            "dogs": float(prob_dog),
        }
        
        return display_text, label_name, confidence_dict, model_info


def scan_weights_folder(weights_dir):
    """æ‰«æ weights æ–‡ä»¶å¤¹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ .pt æ–‡ä»¶ã€‚
    
    å‚æ•°:
        weights_dir: weights æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        
    è¿”å›:
        list: (æ–‡ä»¶è·¯å¾„, æ˜¾ç¤ºåç§°) å…ƒç»„åˆ—è¡¨ï¼ŒæŒ‰æ–‡ä»¶åæ’åºã€‚
    """
    weights_path = Path(weights_dir)
    if not weights_path.exists():
        return []
    
    weight_files = []
    for pt_file in weights_path.glob("*.pt"):
        weight_files.append((str(pt_file.resolve()), pt_file.name))
    
    # æŒ‰æ–‡ä»¶åæ’åº
    weight_files.sort(key=lambda x: x[1])
    return weight_files


def create_gradio_interface(classifier, model_choices, default_model=None, threshold=0.5):
    """åˆ›å»º Gradio ç•Œé¢ã€‚
    
    å‚æ•°:
        classifier: CatDogClassifier å®ä¾‹ã€‚
        model_choices: æ¨¡å‹é€‰æ‹©åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(è·¯å¾„, æ˜¾ç¤ºå), ...]ã€‚
        default_model: é»˜è®¤é€‰æ‹©çš„æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰ã€‚
        threshold: é»˜è®¤æ¦‚ç‡é˜ˆå€¼ï¼ˆfloatï¼Œé»˜è®¤: 0.5ï¼‰ã€‚
        
    è¿”å›:
        gr.Blocks: Gradio ç•Œé¢å¯¹è±¡ã€‚
    """
    # åˆå§‹åŒ–é»˜è®¤æ¨¡å‹ä¿¡æ¯æ˜¾ç¤º
    initial_model_info = ""
    if classifier.model is not None and classifier.checkpoint_path:
        # æ¨¡å‹å·²ç»åŠ è½½ï¼ˆåœ¨ main å‡½æ•°ä¸­åŠ è½½çš„ï¼‰
        model_name = Path(classifier.checkpoint_path).name
        initial_model_info = f"âœ… æ¨¡å‹å·²åŠ è½½: `{model_name}`\n\nğŸ“ å›¾åƒå°ºå¯¸: {classifier.image_size}x{classifier.image_size}\nğŸ¨ æ ‡å‡†åŒ–: {'ImageNet' if classifier.normalize_imagenet else 'é»˜è®¤ [0,1]'}"
    elif default_model and model_choices:
        # å°è¯•åŠ è½½é»˜è®¤æ¨¡å‹
        try:
            classifier.load_model(default_model)
            model_name = Path(default_model).name
            initial_model_info = f"âœ… æ¨¡å‹å·²åŠ è½½: `{model_name}`\n\nğŸ“ å›¾åƒå°ºå¯¸: {classifier.image_size}x{classifier.image_size}\nğŸ¨ æ ‡å‡†åŒ–: {'ImageNet' if classifier.normalize_imagenet else 'é»˜è®¤ [0,1]'}"
        except Exception as e:
            initial_model_info = "âš ï¸ é»˜è®¤æ¨¡å‹åŠ è½½å¤±è´¥: {}".format(str(e))
    
    def predict_fn(image, threshold_value, model_path):
        """Gradio é¢„æµ‹å‡½æ•°ã€‚"""
        # å¦‚æœæ¨¡å‹è·¯å¾„æ”¹å˜ï¼Œå…ˆåŠ è½½æ¨¡å‹
        if model_path and model_path != classifier.checkpoint_path:
            try:
                classifier.load_model(model_path)
            except Exception as e:
                return "âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {}".format(str(e)), None, None, None
        
        result = classifier.predict(image, threshold_value)
        if result is None:
            return """
            <div style="text-align: center; padding: 40px; color: #f44336;">
                <h3>âŒ è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡</h3>
                <p>è¯·åœ¨ä¸Šä¼ åŒºåŸŸé€‰æ‹©æˆ–æ‹–æ‹½ä¸€å¼ å›¾ç‰‡</p>
            </div>
            """, None, None, None
        
        if "error" in result:
            return "âŒ {}".format(result["error"]), None, None, None
        
        label_name = result["label_name"]
        prob_dog = result["prob_dog"]
        prob_cat = result["prob_cat"]
        
        # é€‰æ‹© emoji
        emoji = "ğŸ±" if label_name == "cats" else "ğŸ¶"
        
        # æ¨¡å‹ä¿¡æ¯
        model_info = ""
        if classifier.checkpoint_path:
            model_name = Path(classifier.checkpoint_path).name
            model_info = f"**å½“å‰æ¨¡å‹:** `{model_name}`\n"
        
        # æ ¼å¼åŒ–æ˜¾ç¤ºæ–‡æœ¬ï¼ˆæ›´ç¾è§‚çš„æ ¼å¼ï¼‰
        confidence_color_cat = "#4CAF50" if prob_cat > 0.5 else "#757575"
        confidence_color_dog = "#4CAF50" if prob_dog > 0.5 else "#757575"
        
        display_text = f"""
<div style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; color: white; text-align: center; margin-bottom: 15px;">
    <h2 style="margin: 0; font-size: 32px;">{emoji}</h2>
    <h3 style="margin: 10px 0; font-size: 24px;">é¢„æµ‹ç»“æœ: {label_name.upper()}</h3>
</div>

{model_info}

<div style="background-color: #f5f5f5; padding: 15px; border-radius: 8px; margin: 10px 0;">
    <h4 style="margin-top: 0;">ğŸ“Š ç½®ä¿¡åº¦åˆ†æ</h4>
    <div style="display: flex; justify-content: space-between; align-items: center; margin: 10px 0;">
        <span style="font-size: 18px;">ğŸ± çŒ«:</span>
        <span style="font-weight: bold; color: {confidence_color_cat}; font-size: 20px;">{prob_cat:.2%}</span>
    </div>
    <div style="background-color: #e0e0e0; height: 8px; border-radius: 4px; overflow: hidden; margin: 5px 0;">
        <div style="background-color: {confidence_color_cat}; height: 100%; width: {prob_cat*100}%;"></div>
    </div>
    <div style="display: flex; justify-content: space-between; align-items: center; margin: 10px 0;">
        <span style="font-size: 18px;">ğŸ¶ ç‹—:</span>
        <span style="font-weight: bold; color: {confidence_color_dog}; font-size: 20px;">{prob_dog:.2%}</span>
    </div>
    <div style="background-color: #e0e0e0; height: 8px; border-radius: 4px; overflow: hidden; margin: 5px 0;">
        <div style="background-color: {confidence_color_dog}; height: 100%; width: {prob_dog*100}%;"></div>
    </div>
</div>

<div style="background-color: #e3f2fd; padding: 10px; border-radius: 5px; margin-top: 10px;">
    <strong>ğŸ¯ å½“å‰é˜ˆå€¼:</strong> {threshold_value:.2f}
</div>
"""
        
        # ç½®ä¿¡åº¦å­—å…¸ç”¨äºå¯è§†åŒ–
        confidence_dict = {
            "cats": float(prob_cat),
            "dogs": float(prob_dog),
        }
        
        return display_text, label_name, confidence_dict, None
    
    # å‡†å¤‡æ¨¡å‹é€‰æ‹©åˆ—è¡¨
    model_options = ["è¯·é€‰æ‹©æ¨¡å‹"] + [name for _, name in model_choices]
    model_paths = {"è¯·é€‰æ‹©æ¨¡å‹": None}
    for path, name in model_choices:
        model_paths[name] = path
    
    # é»˜è®¤é€‰æ‹©
    default_choice = "è¯·é€‰æ‹©æ¨¡å‹"
    if default_model and model_choices:
        for path, name in model_choices:
            if path == default_model:
                default_choice = name
                break
    
    with gr.Blocks(title="ğŸ±ğŸ¶ çŒ«ç‹—åˆ†ç±»å™¨") as demo:
        # æ ‡é¢˜åŒºåŸŸ
        with gr.Row():
            gr.Markdown(
                """
                <div style="text-align: center;">
                    <h1 style="margin-bottom: 10px;">ğŸ±ğŸ¶ çŒ«ç‹—å›¾åƒåˆ†ç±»å™¨</h1>
                    <p style="font-size: 16px; color: #666;">ä¸Šä¼ å›¾ç‰‡ï¼ŒAI è‡ªåŠ¨è¯†åˆ«æ˜¯çŒ«è¿˜æ˜¯ç‹—ï¼</p>
                </div>
                """
            )
        
        gr.Markdown("---")
        
        # ä¸»è¦å†…å®¹åŒºåŸŸ
        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥åŒºåŸŸ
            with gr.Column(scale=1, min_width=400):
                # æ¨¡å‹é€‰æ‹©åŒºåŸŸï¼ˆç§»åˆ°å·¦ä¾§ä¸Šæ–¹ï¼‰
                with gr.Group():
                    gr.Markdown("### ğŸ¤– æ¨¡å‹é€‰æ‹©")
                    model_dropdown = gr.Dropdown(
                        choices=model_options,
                        value=default_choice,
                        label="é€‰æ‹©æ¨¡å‹",
                        info="ä» weights æ–‡ä»¶å¤¹ä¸­é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹",
                    )
                    model_info_text = gr.Markdown(
                        label="æ¨¡å‹ä¿¡æ¯",
                        value=initial_model_info,
                        elem_classes=["model-info"],
                    )
                
                with gr.Group():
                    gr.Markdown("### ğŸ“¤ è¾“å…¥åŒºåŸŸ")
                    image_input = gr.Image(
                        type="pil",
                        label="ğŸ“· ä¸Šä¼ å›¾ç‰‡",
                        height=350,
                    )
                
                with gr.Group():
                    gr.Markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
                    threshold_slider = gr.Slider(
                        minimum=0.0,
                        maximum=1.0,
                        value=threshold,
                        step=0.01,
                        label="ğŸ¯ æ¦‚ç‡é˜ˆå€¼",
                        info="è°ƒæ•´åˆ¤æ–­ä¸ºç‹—çš„æ¦‚ç‡é˜ˆå€¼ï¼ˆé»˜è®¤: 0.5ï¼‰",
                    )
                    predict_btn = gr.Button(
                        "ğŸ”® å¼€å§‹é¢„æµ‹",
                        variant="primary",
                        size="lg",
                    )
            
            # å³ä¾§ï¼šç»“æœåŒºåŸŸ
            with gr.Column(scale=1, min_width=400):
                with gr.Group():
                    gr.Markdown("### ğŸ“Š é¢„æµ‹ç»“æœ")
                    result_text = gr.Markdown(
                        value="""
                        <div style="text-align: center; padding: 40px; color: #999;">
                            <h3>ğŸ“¤ ç­‰å¾…ä¸Šä¼ å›¾ç‰‡</h3>
                            <p>è¯·åœ¨ä¸Šä¼ åŒºåŸŸé€‰æ‹©æˆ–æ‹–æ‹½ä¸€å¼ å›¾ç‰‡</p>
                        </div>
                        """,
                        elem_classes=["result-text"],
                    )
                
                with gr.Group():
                    gr.Markdown("### ğŸ“ˆ è¯¦ç»†åˆ†æ")
                    result_label = gr.Textbox(
                        label="ğŸ·ï¸ é¢„æµ‹ç±»åˆ«",
                        interactive=False,
                    )
                    confidence_plot = gr.Label(
                        label="ğŸ“Š ç½®ä¿¡åº¦åˆ†å¸ƒ",
                        num_top_classes=2,
                    )
        
        gr.Markdown("---")
        
        # æ¨¡å‹é€‰æ‹©äº‹ä»¶
        def on_model_change(model_name):
            """æ¨¡å‹é€‰æ‹©æ”¹å˜æ—¶çš„å›è°ƒã€‚"""
            if not model_name or model_name == "è¯·é€‰æ‹©æ¨¡å‹":
                return "âš ï¸ è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹"
            
            model_path = model_paths.get(model_name)
            if not model_path:
                return "âŒ æœªæ‰¾åˆ°æ¨¡å‹è·¯å¾„"
            
            try:
                classifier.load_model(model_path)
                model_name_display = Path(model_path).name
                info_text = f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: `{model_name_display}`\n\nğŸ“ å›¾åƒå°ºå¯¸: {classifier.image_size}x{classifier.image_size}\nğŸ¨ æ ‡å‡†åŒ–: {'ImageNet' if classifier.normalize_imagenet else 'é»˜è®¤ [0,1]'}"
                return info_text
            except Exception as e:
                error_msg = "âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {}".format(str(e))
                return error_msg
        
        model_dropdown.change(
            fn=on_model_change,
            inputs=[model_dropdown],
            outputs=[model_info_text],
        )
        
        # é¢„æµ‹äº‹ä»¶
        def predict_with_model(image, threshold_value, model_name):
            """å¸¦æ¨¡å‹é€‰æ‹©çš„é¢„æµ‹å‡½æ•°ã€‚"""
            if model_name and model_name != "è¯·é€‰æ‹©æ¨¡å‹":
                model_path = model_paths.get(model_name)
                if model_path and model_path != classifier.checkpoint_path:
                    try:
                        classifier.load_model(model_path)
                    except Exception as e:
                        return "âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {}".format(str(e)), None, None, None
            
            return predict_fn(image, threshold_value, None)
        
        # ç»‘å®šäº‹ä»¶
        predict_btn.click(
            fn=predict_with_model,
            inputs=[image_input, threshold_slider, model_dropdown],
            outputs=[result_text, result_label, confidence_plot, model_info_text],
        )
        
        # è‡ªåŠ¨é¢„æµ‹ï¼ˆå½“å›¾ç‰‡ä¸Šä¼ æ—¶ï¼‰
        image_input.change(
            fn=predict_with_model,
            inputs=[image_input, threshold_slider, model_dropdown],
            outputs=[result_text, result_label, confidence_plot, model_info_text],
        )
        
        # é˜ˆå€¼æ”¹å˜æ—¶é‡æ–°é¢„æµ‹
        threshold_slider.change(
            fn=predict_with_model,
            inputs=[image_input, threshold_slider, model_dropdown],
            outputs=[result_text, result_label, confidence_plot, model_info_text],
        )
        
        # åº•éƒ¨æç¤ºåŒºåŸŸ
        with gr.Row():
            with gr.Column():
                gr.Markdown(
                    """
                    <div style="background-color: #f0f7ff; padding: 20px; border-radius: 10px; border-left: 4px solid #4a90e2;">
                        <h4 style="margin-top: 0; color: #4a90e2;">ğŸ’¡ ä½¿ç”¨æç¤º</h4>
                        <ul style="margin-bottom: 0;">
                            <li>æ”¯æŒå¸¸è§å›¾ç‰‡æ ¼å¼ï¼š<strong>JPGã€PNGã€BMPã€GIFã€WEBP</strong></li>
                            <li>å»ºè®®ä¸Šä¼ <strong>æ¸…æ™°çš„çŒ«æˆ–ç‹—çš„ç…§ç‰‡</strong>ä»¥è·å¾—æœ€ä½³æ•ˆæœ</li>
                            <li>è°ƒæ•´é˜ˆå€¼å¯ä»¥æ”¹å˜åˆ†ç±»çš„ä¸¥æ ¼ç¨‹åº¦</li>
                            <li>åˆ‡æ¢æ¨¡å‹åä¼šè‡ªåŠ¨é‡æ–°é¢„æµ‹</li>
                        </ul>
                    </div>
                    """
                )
    
    return demo


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°ã€‚"""
    parser = argparse.ArgumentParser(description="çŒ«ç‹—åˆ†ç±» Gradio Web åº”ç”¨")
    parser.add_argument(
        "--weights-dir",
        default="weights",
        help="æƒé‡æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆé»˜è®¤: weightsï¼‰",
    )
    parser.add_argument(
        "--checkpoint",
        default=None,
        help="é»˜è®¤æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœæŒ‡å®šåˆ™ä½œä¸ºåˆå§‹æ¨¡å‹ï¼‰",
    )
    parser.add_argument(
        "--arch",
        default=None,
        help="æ¨¡å‹æ¶æ„æ ‡è¯†ï¼ˆå¯é€‰ï¼Œè¦†ç›–æ£€æŸ¥ç‚¹é…ç½®ï¼‰",
    )
    parser.add_argument(
        "--device",
        default="auto",
        help="æ¨ç†è®¾å¤‡ï¼Œä¾‹å¦‚ cpu / cuda:0ï¼Œé»˜è®¤è‡ªåŠ¨é€‰æ‹©",
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.5,
        help="é»˜è®¤æ¦‚ç‡é˜ˆå€¼ï¼ˆé»˜è®¤: 0.5ï¼‰",
    )
    parser.add_argument(
        "--server-name",
        default="0.0.0.0",
        help="æœåŠ¡å™¨ç›‘å¬åœ°å€ï¼ˆé»˜è®¤: 0.0.0.0ï¼‰",
    )
    parser.add_argument(
        "--server-port",
        type=int,
        default=7860,
        help="æœåŠ¡å™¨ç«¯å£ï¼ˆé»˜è®¤: 7860ï¼‰",
    )
    parser.add_argument(
        "--share",
        action="store_true",
        help="åˆ›å»ºå…¬å…±é“¾æ¥ï¼ˆé€šè¿‡ Gradio åˆ†äº«ï¼‰",
    )
    return parser.parse_args()


def _resolve_device(device_arg):
    """æ ¹æ®å‚æ•°è§£ææ¨ç†è®¾å¤‡æ ‡è¯†ã€‚"""
    if device_arg and device_arg.lower() != "auto":
        return device_arg
    return "cuda" if torch.cuda.is_available() else "cpu"


def main():
    """ä¸»å‡½æ•°ã€‚"""
    args = parse_args()
    device = _resolve_device(args.device)
    
    print("ğŸ” æ­£åœ¨æ‰«ææƒé‡æ–‡ä»¶å¤¹...")
    weights_dir = Path(args.weights_dir)
    
    # æ‰«ææƒé‡æ–‡ä»¶
    model_choices = scan_weights_folder(weights_dir)
    
    if not model_choices:
        print("âš ï¸ è­¦å‘Š: åœ¨ '{}' æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»»ä½• .pt æ–‡ä»¶".format(weights_dir))
        print("ğŸ’¡ æç¤º: è¯·å°†æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆ.ptï¼‰æ”¾å…¥ weights æ–‡ä»¶å¤¹")
        if args.checkpoint:
            print("ğŸ“ ä½¿ç”¨æŒ‡å®šçš„æ£€æŸ¥ç‚¹: {}".format(args.checkpoint))
            model_choices = [(args.checkpoint, Path(args.checkpoint).name)]
        else:
            print("âŒ é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
            return
    else:
        print("âœ… æ‰¾åˆ° {} ä¸ªæ¨¡å‹æ–‡ä»¶:".format(len(model_choices)))
        for path, name in model_choices:
            print("   - {}".format(name))
    
    print("\nğŸ’» è®¾å¤‡: {}".format(device.upper()))
    
    # ç¡®å®šé»˜è®¤æ¨¡å‹
    default_model = None
    if args.checkpoint:
        # æ£€æŸ¥æŒ‡å®šçš„æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨åˆ—è¡¨ä¸­
        checkpoint_path = Path(args.checkpoint).resolve()
        for path, name in model_choices:
            if Path(path).resolve() == checkpoint_path:
                default_model = path
                break
        if default_model is None:
            # å¦‚æœä¸åœ¨åˆ—è¡¨ä¸­ï¼Œæ·»åŠ åˆ°åˆ—è¡¨
            model_choices.insert(0, (str(checkpoint_path), checkpoint_path.name))
            default_model = str(checkpoint_path)
    elif model_choices:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
        default_model = model_choices[0][0]
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼Œä¸åœ¨åˆå§‹åŒ–æ—¶åŠ è½½æ¨¡å‹ï¼‰
    classifier = CatDogClassifier(
        checkpoint_path=None,  # å»¶è¿ŸåŠ è½½
        device=device,
        arch=args.arch,
    )
    
    # å¦‚æœæœ‰é»˜è®¤æ¨¡å‹ï¼Œå…ˆåŠ è½½å®ƒ
    if default_model:
        print("\nğŸš€ æ­£åœ¨åŠ è½½é»˜è®¤æ¨¡å‹...")
        print("ğŸ“ æ£€æŸ¥ç‚¹: {}".format(default_model))
        try:
            classifier.load_model(default_model)
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
            print("ğŸ“ å›¾åƒå°ºå¯¸: {}x{}".format(classifier.image_size, classifier.image_size))
            print("ğŸ¨ æ ‡å‡†åŒ–: {}".format("ImageNet" if classifier.normalize_imagenet else "é»˜è®¤ [0,1]"))
        except Exception as e:
            print("âŒ é»˜è®¤æ¨¡å‹åŠ è½½å¤±è´¥: {}".format(e))
            print("âš ï¸ å°†åœ¨ç•Œé¢ä¸­é€‰æ‹©æ¨¡å‹")
    
    # åˆ›å»º Gradio ç•Œé¢
    demo = create_gradio_interface(
        classifier,
        model_choices=model_choices,
        default_model=default_model,
        threshold=args.threshold,
    )
    
    # å¯åŠ¨æœåŠ¡
    print("\nğŸŒ æ­£åœ¨å¯åŠ¨ Web æœåŠ¡...")
    print("ğŸ“ è®¿é—®åœ°å€: http://{}:{}".format(args.server_name, args.server_port))
    if args.share:
        print("ğŸ”— å…¬å…±é“¾æ¥å°†åœ¨å¯åŠ¨åæ˜¾ç¤º")
    
    demo.launch(
        server_name=args.server_name,
        server_port=args.server_port,
        share=args.share,
    )


if __name__ == "__main__":
    main()

