import logging
import os
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
import json
import sys

import joblib
import numpy as np
from tqdm import tqdm
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

current_file = Path(__file__).resolve()
project_root = current_file.parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.features.color_hist import extract_color_hist_from_path
from src.features.hog import extract_hog_from_path
from src.features.sift import extract_sift_from_path
from src.features.lbp import extract_lbp_from_path
from src.features.moments import extract_color_moments_from_path, extract_hu_moments_from_path
from src.features.glcm import extract_glcm_from_path
from src.features.gabor import extract_gabor_from_path
from src.features.edge_hist import extract_edge_hist_from_path
from src.features.corner_edge_density import extract_corner_edge_density_from_path


LOGGER = logging.getLogger('feature_extractor')

FEATURE_POOL = [
    'color_hist',
    'hog',
    'sift',
    'lbp',
    'color_moments',
    'hu_moments',
    'glcm',
    'gabor',
    'edge_hist',
    'corner_edge',
]

FEATURE_DEFAULT_CONFIG = {
    'color_hist': {'color_space': 'HSV', 'hist_size': (8, 8, 8)},
    'hog': {
        'orientations': 9,
        'pixels_per_cell': (16, 16),
        'cells_per_block': (2, 2),
        'block_norm': 'L2-Hys',
    },
    'sift': {
        'n_features': 0,
        'n_octave_layers': 3,
        'contrast_threshold': 0.04,
        'edge_threshold': 10,
        'sigma': 1.6,
        'num_scale_bins': 8,
        'num_response_bins': 8,
        'num_angle_bins': 18,
    },
    'lbp': {'P': 8, 'R': 1, 'method': 'uniform'},
    'color_moments': {'color_space': 'HSV'},
    'hu_moments': {'use_edges': False, 'canny_threshold1': 100, 'canny_threshold2': 200},
    'glcm': {
        'distances': (1, 2, 4),
        'angles': (0.0, np.pi / 4, np.pi / 2, 3 * np.pi / 4),
        'levels': 256,
        'symmetric': True,
        'normed': True,
    },
    'gabor': {
        'ksizes': (15,),
        'sigmas': (4.0,),
        'thetas': (0, np.pi / 4, np.pi / 2, 3 * np.pi / 4),
        'lambdas': (10.0, 20.0),
        'gammas': (0.5, 0.8),
        'psis': (0, np.pi / 2),
    },
    'edge_hist': {
        'num_orientation_bins': 9,
        'num_magnitude_bins': 32,
        'canny_threshold1': 100,
        'canny_threshold2': 200,
    },
    'corner_edge': {
        'harris_block_size': 2,
        'harris_ksize': 3,
        'harris_k': 0.04,
        'shi_max_corners': 500,
        'shi_quality_level': 0.01,
        'shi_min_distance': 5,
        'canny_threshold1': 100,
        'canny_threshold2': 200,
    },
}

FEATURE_EXTRACTOR_MAP = {
    'color_hist': extract_color_hist_from_path,
    'hog': extract_hog_from_path,
    'sift': extract_sift_from_path,
    'lbp': extract_lbp_from_path,
    'color_moments': extract_color_moments_from_path,
    'hu_moments': extract_hu_moments_from_path,
    'glcm': extract_glcm_from_path,
    'gabor': extract_gabor_from_path,
    'edge_hist': extract_edge_hist_from_path,
    'corner_edge': extract_corner_edge_density_from_path,
}

DEFAULT_SPLITS = ('train', 'val', 'test')


def collect_image_paths_and_labels(dataset_dir, split='train'):
    """æ”¶é›†æ•°æ®é›†åˆ†å‰²ä¸­çš„å›¾åƒè·¯å¾„ä¸æ ‡ç­¾ã€‚

    å‚æ•°:
        dataset_dir: æ•°æ®é›†æ ¹ç›®å½•
        split: åˆ†å‰²åç§° (train/val/test)

    è¿”å›:
        tuple: ``(paths, labels)`` åˆ—è¡¨

    å¼‚å¸¸:
        FileNotFoundError: å½“åˆ†å‰²ç›®å½•ä¸å­˜åœ¨æ—¶æŠ›å‡º
    """
    dataset_dir = Path(dataset_dir)
    split_dir = dataset_dir / split
    if not split_dir.exists():
        raise FileNotFoundError('æ•°æ®é›†åˆ†å‰²ç›®å½•ä¸å­˜åœ¨: {}'.format(split_dir))

    paths = []
    labels = []
    class_map = (('cats', 0), ('dogs', 1))

    for class_name, label in class_map:
        class_dir = split_dir / class_name
        if not class_dir.exists():
            continue
        for pattern in ('*.jpg', '*.jpeg', '*.png'):
            for image_path in sorted(class_dir.glob(pattern)):
                paths.append(str(image_path))
                labels.append(label)

    return paths, labels


def save_features_to_file(features, labels, valid_indices, feature_info, save_path):
    """ä¿å­˜ç‰¹å¾çŸ©é˜µä¸å…ƒæ•°æ®ã€‚

    å‚æ•°:
        features: numpy.ndarray ç‰¹å¾çŸ©é˜µ
        labels: numpy.ndarray æˆ– Noneï¼Œç‰¹å¾å¯¹åº”æ ‡ç­¾
        valid_indices: listï¼ŒæˆåŠŸæå–çš„åŸå§‹ç´¢å¼•
        feature_info: dictï¼Œé¢å¤–è®°å½•çš„ç‰¹å¾ä¿¡æ¯
        save_path: joblib æ–‡ä»¶ä¿å­˜è·¯å¾„
    """
    save_path = Path(save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)

    payload = {
        'features': features,
        'labels': labels,
        'valid_indices': list(valid_indices),
        'feature_info': feature_info,
        'feature_shape': features.shape,
        'n_samples': int(features.shape[0]),
        'n_features': int(features.shape[1]) if len(features.shape) == 2 else 0,
    }
    joblib.dump(payload, save_path)
    LOGGER.info('ğŸ’¾ ç‰¹å¾å·²ä¿å­˜: %s', save_path)


class UnifiedFeatureExtractor:
    """æ ¹æ®é…ç½®æå–å¹¶æ‹¼æ¥å¤šç§ç»å…¸å›¾åƒç‰¹å¾ã€‚"""
    
    _single_extractor_cache = {}  # ç±»çº§åˆ«çš„å•ç‰¹å¾æå–å™¨ç¼“å­˜

    @staticmethod
    def normalize_feature_config(feature_config):
        """æ ¡éªŒå¹¶æ•´ç†ç‰¹å¾é…ç½®ã€‚

        å‚æ•°:
            feature_config: dictï¼Œè‡ªå®šä¹‰ç‰¹å¾é…ç½®

        è¿”å›:
            dict: æ¸…æ´—åçš„é…ç½®å­—å…¸

        å¼‚å¸¸:
            ValueError: å½“é…ç½®åŒ…å«æœªçŸ¥ç‰¹å¾æ—¶æŠ›å‡º
        """
        if feature_config is None:
            return dict(FEATURE_DEFAULT_CONFIG)
        
        if not isinstance(feature_config, dict):
            raise ValueError('feature_config å¿…é¡»æ˜¯å­—å…¸')

        normalized = {}
        for name, params in feature_config.items():
            if name not in FEATURE_EXTRACTOR_MAP:
                raise ValueError('æœªçŸ¥çš„ç‰¹å¾ç±»å‹: {}'.format(name))
            normalized[name] = params or {}
        return normalized

    def __init__(self, feature_config=None, image_size=128, n_jobs=None, verbose=True):
        """åˆå§‹åŒ–ç‰¹å¾æå–å™¨ã€‚

        å‚æ•°:
            feature_config: dictï¼Œç‰¹å¾ç±»å‹åˆ°å‚æ•°çš„æ˜ å°„
            image_size: intï¼Œå›¾åƒç¼©æ”¾å°ºå¯¸
            n_jobs: int æˆ– Noneï¼Œçº¿ç¨‹æ± å¹¶å‘æ•° (None è¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©ï¼Œ1 è¡¨ç¤ºç¦ç”¨å¹¶å‘)
            verbose: boolï¼Œæ˜¯å¦è¾“å‡ºè¿›åº¦ä¿¡æ¯
        """
        self.image_size = int(image_size)
        self.verbose = bool(verbose)
        if n_jobs is None:
            cpu_count = os.cpu_count() or 1
            self.n_jobs = max(1, min(4, cpu_count))
        else:
            self.n_jobs = max(1, int(n_jobs))
        self.feature_config = self.normalize_feature_config(feature_config)

    def _extract_feature(self, image_path, feature_type, params):
        extractor = FEATURE_EXTRACTOR_MAP.get(feature_type)
        if extractor is None:
            raise ValueError('æœªçŸ¥çš„ç‰¹å¾ç±»å‹: {}'.format(feature_type))
        kwargs = {'image_size': self.image_size}
        kwargs.update(params or {})
        return extractor(image_path, **kwargs)

    def extract_features_from_image(self, image_path):
        """æå–å•å¼ å›¾åƒçš„ç‰¹å¾å‘é‡ã€‚

        å‚æ•°:
            image_path: strï¼Œå›¾åƒè·¯å¾„

        è¿”å›:
            numpy.ndarray æˆ– None: æ‹¼æ¥åçš„ç‰¹å¾å‘é‡
        """
        vectors = []
        for feature_type, params in self.feature_config.items():
            try:
                feature_vector = self._extract_feature(image_path, feature_type, params)
            except Exception as exc:
                if self.verbose:
                    LOGGER.warning('æå–å¤±è´¥ %s (%s): %s', feature_type, image_path, exc)
                feature_vector = None
            if feature_vector is not None:
                vectors.append(feature_vector)
        if not vectors:
            return None
        return np.concatenate(vectors, axis=0).astype(np.float32)

    def extract_features_batch(self, image_paths, labels=None):
        """æ‰¹é‡æå–å›¾åƒç‰¹å¾ã€‚

        å‚æ•°:
            image_paths: listï¼Œå›¾åƒè·¯å¾„åˆ—è¡¨
            labels: list æˆ– Noneï¼Œå¯¹åº”æ ‡ç­¾

        è¿”å›:
            tuple: ``(features, label_array, valid_indices)``

        å¼‚å¸¸:
            RuntimeError: å½“å…¨éƒ¨å›¾åƒæå–å¤±è´¥æ—¶æŠ›å‡º
        """
        if self.verbose:
            LOGGER.info('ğŸ” å¼€å§‹æ‰¹é‡ç‰¹å¾æå–...')
            LOGGER.info('   å›¾åƒæ•°é‡: {}'.format(len(image_paths)))
            LOGGER.info('   ç‰¹å¾ç±»å‹: {}'.format(list(self.feature_config.keys())))
            LOGGER.info('   å¹¶è¡Œçº¿ç¨‹: {}'.format(self.n_jobs))

        features = []
        selected_labels = []
        valid_indices = []
        use_parallel = self.n_jobs > 1

        # åˆ›å»ºè¿›åº¦æ¡
        progress = None
        if self.verbose:
            progress = tqdm(total=len(image_paths), desc='æå–ç‰¹å¾', leave=False)

        try:
            if use_parallel:
                with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:
                    futures = [
                        (idx, executor.submit(self.extract_features_from_image, image_path))
                        for idx, image_path in enumerate(image_paths)
                    ]
                    for idx, future in futures:
                        vector = future.result()
                        if vector is not None:
                            features.append(vector)
                            valid_indices.append(idx)
                            if labels is not None:
                                selected_labels.append(labels[idx])
                        if progress is not None:
                            progress.update(1)
            else:
                for idx, image_path in enumerate(image_paths):
                    vector = self.extract_features_from_image(image_path)
                    if vector is not None:
                        features.append(vector)
                        valid_indices.append(idx)
                        if labels is not None:
                            selected_labels.append(labels[idx])
                    if progress is not None:
                        progress.update(1)
        finally:
            if progress is not None:
                progress.close()

        if not features:
            raise RuntimeError('æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰¹å¾')

        feature_matrix = np.vstack(features).astype(np.float32)
        label_array = None
        if labels is not None and selected_labels:
            label_array = np.array(selected_labels)

        if self.verbose:
            LOGGER.info('âœ… ç‰¹å¾æå–å®Œæˆ: {}/{} æ ·æœ¬'.format(len(valid_indices), len(image_paths)))
            LOGGER.info('   ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {}'.format(feature_matrix.shape))

        return feature_matrix, label_array, valid_indices

    @classmethod
    def extract_single_feature_matrix(cls, image_paths, labels, feature_type, image_size=128, n_jobs=None, show_progress=True):
        """æå–å•ä¸€ç‰¹å¾ç±»å‹çš„ç‰¹å¾çŸ©é˜µã€‚

        å‚æ•°:
            image_paths: listï¼Œå›¾åƒè·¯å¾„
            labels: listï¼Œæ ‡ç­¾åˆ—è¡¨
            feature_type: strï¼Œè¦è¯„ä¼°çš„ç‰¹å¾ç±»å‹
            image_size: intï¼Œå›¾åƒç¼©æ”¾å°ºå¯¸
            n_jobs: int æˆ– Noneï¼Œå¹¶è¡Œçº¿ç¨‹æ•°
            show_progress: boolï¼Œæ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡

        è¿”å›:
            dict: åŒ…å«ç‰¹å¾çŸ©é˜µä¸å…ƒæ•°æ®çš„å­—å…¸
        """
        if feature_type not in FEATURE_EXTRACTOR_MAP:
            raise ValueError('æœªçŸ¥çš„ç‰¹å¾ç±»å‹: {}'.format(feature_type))

        cache_key = (feature_type, image_size, n_jobs)
        extractor = cls._single_extractor_cache.get(cache_key)
        if extractor is None:
            extractor = cls(
                feature_config={feature_type: FEATURE_DEFAULT_CONFIG.get(feature_type, {})},
                image_size=image_size,
                n_jobs=n_jobs,
                verbose=show_progress,
            )
            cls._single_extractor_cache[cache_key] = extractor
        features, label_array, valid_indices = extractor.extract_features_batch(image_paths, labels)

        payload = {
            'X': features.astype(np.float32),
            'y': label_array.astype(np.int64) if label_array is not None else None,
            'valid_indices': list(valid_indices),
            'dim': int(features.shape[1]) if len(features.shape) == 2 else 0,
        }

        return payload

    @classmethod
    def extract_and_save_dataset_features(cls, dataset_dir='dataset', save_dir='features', feature_config=None,
                                          image_size=128, n_jobs=None):
        """ä¸ºæ ‡å‡†æ•°æ®é›†åˆ†å‰²æå–ç‰¹å¾å¹¶ä¿å­˜ã€‚

        å‚æ•°:
            dataset_dir: æ•°æ®é›†æ ¹ç›®å½•
            save_dir: ç‰¹å¾ä¿å­˜ç›®å½•
            feature_config: dictï¼Œè‡ªå®šä¹‰ç‰¹å¾é…ç½®
            image_size: intï¼Œå›¾åƒç¼©æ”¾å°ºå¯¸
            n_jobs: int æˆ– Noneï¼Œå¹¶è¡Œçº¿ç¨‹æ•°

        è¿”å›:
            dict: å„åˆ†å‰²çš„æå–ç»“æœç»Ÿè®¡
        """
        extractor = cls(
            feature_config=feature_config,
            image_size=image_size,
            n_jobs=n_jobs,
            verbose=True,
        )

        results = {}
        for split in DEFAULT_SPLITS:
            LOGGER.info('ğŸ”„ å¼€å§‹å¤„ç† %s åˆ†å‰²', split)
            try:
                image_paths, labels = collect_image_paths_and_labels(dataset_dir, split)
            except FileNotFoundError as exc:
                LOGGER.warning('è·³è¿‡ %s: %s', split, exc)
                continue

            if not image_paths:
                LOGGER.warning('%s åˆ†å‰²æ²¡æœ‰å›¾åƒï¼Œè·³è¿‡', split)
                continue

            features, label_array, valid_indices = extractor.extract_features_batch(image_paths, labels)
            info = {
                'feature_config': extractor.feature_config,
                'image_size': image_size,
                'total_dim': int(features.shape[1]) if len(features.shape) == 2 else 0,
            }
            save_path = Path(save_dir) / split / '{}_features.joblib'.format(split)
            save_features_to_file(features, label_array, valid_indices, info, save_path)

            results[split] = {
                'n_total': len(image_paths),
                'n_valid': len(valid_indices),
                'feature_shape': features.shape,
                'save_path': str(save_path),
            }
            LOGGER.info('âœ… %s åˆ†å‰²å®Œæˆ: %d/%d æ ·æœ¬', split, len(valid_indices), len(image_paths))

        return results


if __name__ == '__main__':
    # è¯»å–æŸæœç´¢äº§ç”Ÿçš„æœ€ä½³ç‰¹å¾ç»„åˆ
    results_json = Path('runs/feature_search/search_results.json')
    try:
        with open(results_json, 'r', encoding='utf-8') as f:
            results = json.load(f)
        best_subset = results.get('best_result', {}).get('subset', [])
        config_block = results.get('config', {}) or {}
        image_size = int(config_block.get('image_size', 128))
        n_jobs = config_block.get('n_jobs', None)
        if n_jobs is not None:
            n_jobs = int(n_jobs)
        LOGGER.info('ğŸŸ¢ ä½¿ç”¨ search_results.json ä¸­çš„æœ€ä½³é…ç½®: %s', ' + '.join(best_subset) if best_subset else '(ç©º)')
    except Exception as exc:
        LOGGER.warning('æ— æ³•è¯»å–æœ€ä½³é…ç½® (%s)ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®: %s', exc, str(results_json))
        best_subset = []
        image_size = 128
        n_jobs = None

    # åŸºäºæœ€ä½³å­é›†æ„å»º feature_configï¼›è‹¥ä¸ºç©ºåˆ™å›é€€åˆ°é»˜è®¤é…ç½®ï¼ˆä½¿ç”¨ FEATURE_DEFAULT_CONFIGï¼‰
    if best_subset:
        feature_config = {name: FEATURE_DEFAULT_CONFIG.get(name, {}) for name in best_subset if name in FEATURE_EXTRACTOR_MAP}
    else:
        feature_config = dict(FEATURE_DEFAULT_CONFIG)

    # åŸºç¡€æ—¥å¿—é…ç½®ï¼ˆä»…åœ¨æœªé…ç½®è¿‡æ—¶ç”Ÿæ•ˆï¼‰
    if not logging.getLogger().handlers:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s | %(name)s | %(levelname)s | %(message)s'
        )

    LOGGER.info('ğŸ“¦ å¼€å§‹æ ¹æ®æœ€ä½³é…ç½®æå–æ•°æ®é›†ç‰¹å¾')
    LOGGER.info('   æ•°æ®é›†ç›®å½•: %s', 'dataset')
    LOGGER.info('   ä¿å­˜ç›®å½•: %s', 'features')
    LOGGER.info('   å›¾åƒå°ºå¯¸: %d', image_size)
    LOGGER.info('   å¹¶è¡Œçº¿ç¨‹: %s', str(n_jobs) if n_jobs else '(auto)')
    LOGGER.info('   ç‰¹å¾ç±»å‹: %s', ', '.join(sorted(feature_config.keys())))

    try:
        # ä½¿ç”¨ç»Ÿä¸€æå–å™¨æå–åŸå§‹ç‰¹å¾ï¼ˆä¸åš PCAï¼‰ï¼ŒéšååŸºäºè®­ç»ƒé›†æ‹Ÿåˆå¹¶ä¸€è‡´åœ°åº”ç”¨åˆ° val/test
        extractor = UnifiedFeatureExtractor(
            feature_config=feature_config,
            image_size=image_size,
            n_jobs=n_jobs,
            verbose=True,
        )

        raw = {}
        for split in DEFAULT_SPLITS:
            try:
                image_paths, labels = collect_image_paths_and_labels('dataset', split)
            except FileNotFoundError as exc:
                LOGGER.warning('è·³è¿‡ %s: %s', split, exc)
                continue
            if not image_paths:
                LOGGER.warning('%s åˆ†å‰²æ²¡æœ‰å›¾åƒï¼Œè·³è¿‡', split)
                continue
            X, y, idx = extractor.extract_features_batch(image_paths, labels)
            raw[split] = {'X': X, 'y': y, 'idx': idx}
            LOGGER.info('âœ… åŸå§‹ç‰¹å¾å®Œæˆ %s: %d/%d | å½¢çŠ¶ %s', split, len(idx), len(image_paths), X.shape)

        # ä¸æœç´¢ç»“æœå¯¹é½ï¼šå§‹ç»ˆæ ‡å‡†åŒ–ï¼›PCA ç»´åº¦ä¸¥æ ¼ä¾æ® search_results.json çš„ best_result.pca
        if 'train' not in raw:
            raise RuntimeError('ç¼ºå°‘è®­ç»ƒé›†ï¼Œæ— æ³•æ‹Ÿåˆæ ‡å‡†åŒ–ä¸PCA')

        # ä» search_results.json è¯»å– pca ç»´åº¦ï¼ˆ>0 å¯ç”¨ï¼›å¦åˆ™ä¸å¯ç”¨ï¼‰
        try:
            pca_components = int((results or {}).get('best_result', {}).get('pca', 0))
        except Exception:
            pca_components = 0
        apply_pca = pca_components is not None and pca_components > 0

        LOGGER.info('ğŸ§ª æ‹Ÿåˆ StandardScalerï¼ˆåŸºäºè®­ç»ƒé›†ï¼‰')
        scaler = StandardScaler(with_mean=True, with_std=True)
        X_train_scaled = scaler.fit_transform(raw['train']['X'])

        transformed = {}
        if apply_pca:
            LOGGER.info('ğŸ§ª æ ¹æ® JSON æŒ‡å®šæ‰§è¡Œ PCA(%d)', pca_components)
            pca = PCA(n_components=pca_components, random_state=42)
            transformed['train'] = pca.fit_transform(X_train_scaled)
        else:
            LOGGER.info('ğŸ§ª JSON æœªæŒ‡å®šæœ‰æ•ˆ PCA ç»´åº¦ï¼ˆæˆ–ä¸º 0ï¼‰ï¼Œä¸æ‰§è¡Œ PCA')
            pca = None
            transformed['train'] = X_train_scaled

        # åº”ç”¨åˆ°å„åˆ†å‰²
        for split in ('val', 'test'):
            if split in raw:
                X_scaled = scaler.transform(raw[split]['X'])
                transformed[split] = pca.transform(X_scaled) if pca is not None else X_scaled

        # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆæºå¸¦ scaler ä¸ pcaï¼‰
        for split in ('train', 'val', 'test'):
            if split not in raw:
                continue
            X_out = transformed[split]
            y_out = raw[split]['y']
            idx_out = raw[split]['idx']
            info = {
                'feature_config': extractor.feature_config,
                'image_size': image_size,
                'original_dim': int(raw[split]['X'].shape[1]),
                'pca': pca_components,
                'scaler': scaler,
                'pca_model': pca,
                'applied_standardization': True,
                'applied_pca': apply_pca,
            }
            save_path = Path('features') /  f'{split}_features.joblib'
            save_features_to_file(X_out, y_out, idx_out, info, save_path)
            LOGGER.info('ğŸ’¾ å·²ä¿å­˜: %s -> %s | å½¢çŠ¶ %s', split, save_path, X_out.shape)
    except Exception as exc:
        LOGGER.error('æå–è¿‡ç¨‹å¤±è´¥: %s', exc)