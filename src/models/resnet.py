"""
çŒ«ç‹—åˆ†ç±» - ResNeté¢„è®­ç»ƒæ¨¡å‹

è¯¥æ¨¡å—å®ç°äº†åŸºäºPyTorché¢„è®­ç»ƒResNetæ¨¡å‹çš„è¿ç§»å­¦ä¹ ã€‚
åˆ©ç”¨åœ¨ImageNetä¸Šé¢„è®­ç»ƒçš„æƒé‡ï¼Œé€šè¿‡å¾®è°ƒæ¥é€‚åº”çŒ«ç‹—åˆ†ç±»ä»»åŠ¡ã€‚

ä¸»è¦åŠŸèƒ½:
    - æ”¯æŒå¤šç§ResNetæ¶æ„ï¼ˆResNet18, ResNet34, ResNet50ç­‰ï¼‰
    - å¯é€‰çš„ç‰¹å¾æå–æ¨¡å¼å’Œå¾®è°ƒæ¨¡å¼
    - è‡ªé€‚åº”åˆ†ç±»å¤´ï¼Œæ”¯æŒä¸åŒçš„è¾“å‡ºç»´åº¦
    - æ¸è¿›å¼è§£å†»è®­ç»ƒç­–ç•¥
"""
import torch
import torch.nn as nn
from torchvision import models


class PretrainedResNet(nn.Module):
    """é¢„è®­ç»ƒResNetæ¨¡å‹ç±»
    
    åŸºäºtorchvisioné¢„è®­ç»ƒæ¨¡å‹ï¼Œé€šè¿‡æ›¿æ¢åˆ†ç±»å¤´æ¥é€‚åº”çŒ«ç‹—åˆ†ç±»ä»»åŠ¡ã€‚
    æ”¯æŒç‰¹å¾æå–å’Œå¾®è°ƒä¸¤ç§è®­ç»ƒæ¨¡å¼ã€‚
    
    å‚æ•°:
        model_name: ResNetæ¨¡å‹åç§° ('resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152')
        num_classes: è¾“å‡ºç±»åˆ«æ•°ï¼ˆäºŒåˆ†ç±»é€šå¸¸ä¸º1ï¼‰
        pretrained: æ˜¯å¦ä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡
        freeze_backbone: æ˜¯å¦å†»ç»“ä¸»å¹²ç½‘ç»œï¼ˆä»…è®­ç»ƒåˆ†ç±»å¤´ï¼‰
        dropout_p: åˆ†ç±»å¤´ä¸­çš„Dropoutæ¦‚ç‡
    """
    
    def __init__(self, model_name='resnet18', num_classes=1, pretrained=True, freeze_backbone=False, dropout_p=0.5):
        super().__init__()
        
        self.model_name = model_name
        self.num_classes = num_classes
        self.freeze_backbone = freeze_backbone
        
        # éªŒè¯æ¨¡å‹åç§°
        available_models = ['resnet18', 'resnet34', 'resnet50']
        if model_name not in available_models:
            raise ValueError(f"æ¨¡å‹åç§°å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {available_models}")
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if model_name == 'resnet18':
            self.backbone = models.resnet18(pretrained=pretrained)
        elif model_name == 'resnet34':
            self.backbone = models.resnet34(pretrained=pretrained)
        elif model_name == 'resnet50':
            self.backbone = models.resnet50(pretrained=pretrained)
        
        # è·å–åŸå§‹åˆ†ç±»å¤´çš„è¾“å…¥ç»´åº¦
        num_features = self.backbone.fc.in_features
        
        # å°†ResNetçš„fcæ›¿æ¢ä¸ºIdentityï¼Œå¹¶å•ç‹¬å®šä¹‰åˆ†ç±»å¤´
        self.backbone.fc = nn.Identity()
        self.classifier = nn.Sequential(
            nn.Dropout(p=dropout_p) if dropout_p > 0 else nn.Identity(),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout_p) if dropout_p > 0 else nn.Identity(),
            nn.Linear(512, num_classes)
        )
        
        # å¯é€‰åœ°å†»ç»“ä¸»å¹²ç½‘ç»œ
        if freeze_backbone:
            self._freeze_backbone()
    
    def _freeze_backbone(self):
        """å†»ç»“ä¸»å¹²ç½‘ç»œå‚æ•°ï¼Œåªè®­ç»ƒåˆ†ç±»å¤´"""
        for param in self.backbone.parameters():
            param.requires_grad = False
        print("ğŸ§Š å·²å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œä»…è®­ç»ƒåˆ†ç±»å¤´")
    
    def unfreeze_backbone(self):
        """è§£å†»ä¸»å¹²ç½‘ç»œï¼Œå…è®¸å¾®è°ƒæ•´ä¸ªç½‘ç»œ"""
        for param in self.backbone.parameters():
            param.requires_grad = True
        self.freeze_backbone = False
        print("ğŸ”¥ å·²è§£å†»ä¸»å¹²ç½‘ç»œï¼Œå¼€å¯å¾®è°ƒæ¨¡å¼")
    
    def unfreeze_last_n_layers(self, n=1):
        """è§£å†»æœ€ånä¸ªResNetå—
        
        å‚æ•°:
            n: è¦è§£å†»çš„ResNetå—æ•°é‡
        """
        # ResNetçš„ä¸»è¦å—ï¼šlayer1, layer2, layer3, layer4
        layers = [self.backbone.layer4, self.backbone.layer3, self.backbone.layer2, self.backbone.layer1]
        
        # å…ˆå†»ç»“æ‰€æœ‰å±‚
        self._freeze_backbone()
        
        # è§£å†»æœ€ånä¸ªå±‚
        for i in range(min(n, len(layers))):
            for param in layers[i].parameters():
                param.requires_grad = True
        
        print(f"ğŸ”“ å·²è§£å†»æœ€å {min(n, len(layers))} ä¸ªResNetå±‚")
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­
        
        å‚æ•°:
            x: è¾“å…¥å›¾åƒå¼ é‡ï¼Œå½¢çŠ¶ä¸º (N, C, H, W)
               N: batch size
               C: é€šé“æ•°ï¼ˆRGBä¸º3ï¼‰
               H, W: å›¾åƒé«˜åº¦å’Œå®½åº¦
        
        è¿”å›:
            è¾“å‡ºlogitsï¼Œå½¢çŠ¶ä¸º (N, num_classes)
        """
        features = self.backbone(x)
        return self.classifier(features)
    
    def get_trainable_params(self):
        """è·å–å¯è®­ç»ƒå‚æ•°çš„ä¿¡æ¯
        
        è¿”å›:
            åŒ…å«å‚æ•°ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'frozen_params': total_params - trainable_params,
            'trainable_ratio': trainable_params / total_params if total_params > 0 else 0
        }


class ResNetTrainer:
    """ResNetè®­ç»ƒå™¨ç±»
    
    å°è£…äº†é¢„è®­ç»ƒResNetæ¨¡å‹çš„è®­ç»ƒæµç¨‹ï¼Œæ”¯æŒæ¸è¿›å¼è§£å†»ç­–ç•¥ã€‚
    
    å‚æ•°:
        model_name: ResNetæ¶æ„åç§°
        num_classes: è¾“å‡ºç±»åˆ«æ•°
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        dropout_p: Dropoutæ¦‚ç‡
        device: è®­ç»ƒè®¾å¤‡ ('cuda' æˆ– 'cpu')
    """
    
    def __init__(self, model_name='resnet18', num_classes=1, pretrained=True, dropout_p=0.5, device='cuda'):
        self.model_name = model_name
        self.num_classes = num_classes
        self.pretrained = pretrained
        self.dropout_p = dropout_p
        self.device = device
        self.model = None
        self.optimizer = None
        self.criterion = None
        
    def build_model(self, freeze_backbone=True):
        """æ„å»ºResNetæ¨¡å‹
        
        å‚æ•°:
            freeze_backbone: æ˜¯å¦å†»ç»“ä¸»å¹²ç½‘ç»œ
            
        è¿”å›:
            æ„å»ºå¥½çš„æ¨¡å‹
        """
        self.model = PretrainedResNet(
            model_name=self.model_name,
            num_classes=self.num_classes,
            pretrained=self.pretrained,
            freeze_backbone=freeze_backbone,
            dropout_p=self.dropout_p
        )
        
        # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.model = self.model.to(self.device)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        params_info = self.model.get_trainable_params()
        print(f"ğŸ—ï¸  æ„å»º {self.model_name} æ¨¡å‹:")
        print(f"   æ€»å‚æ•°: {params_info['total_params']:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {params_info['trainable_params']:,}")
        print(f"   å¯è®­ç»ƒæ¯”ä¾‹: {params_info['trainable_ratio']:.2%}")
        
        return self.model
    
    def setup_training(self, learning_rate=1e-4, weight_decay=1e-4):
        """è®¾ç½®è®­ç»ƒç»„ä»¶ï¼ˆä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼‰
        
        å‚æ•°:
            learning_rate: å­¦ä¹ ç‡
            weight_decay: æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰
        """
        if self.model is None:
            raise RuntimeError("è¯·å…ˆè°ƒç”¨build_model()æ„å»ºæ¨¡å‹")
        
        # ä¸ºå†»ç»“å’Œæœªå†»ç»“çš„å‚æ•°è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡
        if self.model.freeze_backbone:
            # ç‰¹å¾æå–æ¨¡å¼ï¼šåªè®­ç»ƒåˆ†ç±»å¤´
            params = [{'params': self.model.classifier.parameters(), 'lr': learning_rate}]
        else:
            # å¾®è°ƒæ¨¡å¼ï¼šä¸»å¹²ç½‘ç»œä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡ï¼Œåˆ†ç±»å¤´ä½¿ç”¨è¾ƒå¤§å­¦ä¹ ç‡
            backbone_params = []
            for name, param in self.model.backbone.named_parameters():
                if param.requires_grad:
                    backbone_params.append(param)
            
            params = [
                {'params': backbone_params, 'lr': learning_rate * 0.1},  # ä¸»å¹²ç½‘ç»œç”¨è¾ƒå°å­¦ä¹ ç‡
                {'params': self.model.classifier.parameters(), 'lr': learning_rate}  # åˆ†ç±»å¤´ç”¨æ­£å¸¸å­¦ä¹ ç‡
            ]
        
        self.optimizer = torch.optim.Adam(params, weight_decay=weight_decay)
        self.criterion = nn.BCEWithLogitsLoss() if self.num_classes == 1 else nn.CrossEntropyLoss()
        
        print(f"âš™ï¸  è®­ç»ƒé…ç½®:")
        print(f"   ä¼˜åŒ–å™¨: Adam")
        print(f"   å­¦ä¹ ç‡: {learning_rate}")
        print(f"   æƒé‡è¡°å‡: {weight_decay}")
        print(f"   æŸå¤±å‡½æ•°: {'BCEWithLogitsLoss' if self.num_classes == 1 else 'CrossEntropyLoss'}")
    
    def progressive_unfreeze(self, stage):
        """æ¸è¿›å¼è§£å†»ç­–ç•¥
        
        å‚æ•°:
            stage: è§£å†»é˜¶æ®µ
                0: åªè®­ç»ƒåˆ†ç±»å¤´
                1: è§£å†»æœ€å1ä¸ªResNetå—
                2: è§£å†»æœ€å2ä¸ªResNetå—  
                3: è§£å†»æ•´ä¸ªç½‘ç»œ
        """
        if self.model is None:
            raise RuntimeError("è¯·å…ˆæ„å»ºæ¨¡å‹")
        
        if stage == 0:
            self.model._freeze_backbone()
        elif stage == 1:
            self.model.unfreeze_last_n_layers(1)
        elif stage == 2:
            self.model.unfreeze_last_n_layers(2)
        elif stage >= 3:
            self.model.unfreeze_backbone()
        
        # é‡æ–°è®¾ç½®ä¼˜åŒ–å™¨ä»¥åŒ…å«æ–°çš„å¯è®­ç»ƒå‚æ•°
        if self.optimizer is not None:
            lr = self.optimizer.param_groups[0]['lr']
            weight_decay = self.optimizer.param_groups[0]['weight_decay']
            self.setup_training(learning_rate=lr, weight_decay=weight_decay)


def create_resnet18(num_classes=1, pretrained=True, freeze_backbone=True, dropout_p=0.5):
    """åˆ›å»ºResNet18æ¨¡å‹çš„ä¾¿æ·å‡½æ•°
    
    å‚æ•°:
        num_classes: è¾“å‡ºç±»åˆ«æ•°
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        freeze_backbone: æ˜¯å¦å†»ç»“ä¸»å¹²ç½‘ç»œ
        dropout_p: åˆ†ç±»å¤´çš„Dropoutæ¦‚ç‡ï¼ˆfloatï¼Œé»˜è®¤: 0.5ï¼‰
        
    è¿”å›:
        PretrainedResNetå®ä¾‹
    """
    return PretrainedResNet('resnet18', num_classes, pretrained, freeze_backbone, dropout_p=dropout_p)


def create_resnet50(num_classes=1, pretrained=True, freeze_backbone=True, dropout_p=0.5):
    """åˆ›å»ºResNet50æ¨¡å‹çš„ä¾¿æ·å‡½æ•°
    
    å‚æ•°:
        num_classes: è¾“å‡ºç±»åˆ«æ•°
        pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        freeze_backbone: æ˜¯å¦å†»ç»“ä¸»å¹²ç½‘ç»œ
        dropout_p: åˆ†ç±»å¤´çš„Dropoutæ¦‚ç‡ï¼ˆfloatï¼Œé»˜è®¤: 0.5ï¼‰
        
    è¿”å›:
        PretrainedResNetå®ä¾‹
    """
    return PretrainedResNet('resnet50', num_classes, pretrained, freeze_backbone, dropout_p=dropout_p)


def create_resnet_trainer(model_name='resnet18', **kwargs):
    """åˆ›å»ºResNetè®­ç»ƒå™¨çš„å·¥å‚å‡½æ•°
    
    å‚æ•°:
        model_name: ResNetæ¶æ„åç§°
        **kwargs: ResNetTrainerçš„å…¶ä»–å‚æ•°
        
    è¿”å›:
        ResNetTrainerå®ä¾‹
    """
    return ResNetTrainer(model_name=model_name, **kwargs)
