"""
æ¨ç†è„šæœ¬é€šç”¨å·¥å…·å‡½æ•°é›†åˆã€‚

è¯¥æ¨¡å—æä¾›åŠ è½½æ¨¡å‹ã€å‡†å¤‡æ•°æ®ä¸æ‰§è¡Œæ‰¹é‡æ¨ç†çš„å·¥å…·å‡½æ•°ï¼Œ
ä¾›å‘½ä»¤è¡Œæ¨ç†è„šæœ¬å’Œå…¶ä»–ä¸Šå±‚åº”ç”¨å¤ç”¨ã€‚
"""

import logging
from pathlib import Path

import torch
from torch.utils.data import DataLoader, Dataset
from PIL import Image
from tqdm import tqdm

from src.models.cnn import create_CatDogCNNv1, create_CatDogCNNv2
from src.models.resnet import PretrainedResNet


CLASS_NAMES = ["cats", "dogs"]
LOGGER = logging.getLogger(__name__)


def collect_image_paths(input_path, recursive=True, allowed_suffixes=None):
    """æ”¶é›†å¾…æ¨ç†çš„å›¾åƒè·¯å¾„åˆ—è¡¨ã€‚
    
    å‚æ•°:
        input_path: è¾“å…¥èµ„æºè·¯å¾„ï¼Œå¯ä»¥æ˜¯å›¾ç‰‡æ–‡ä»¶ã€ç›®å½•ã€TXT/CSV åˆ—è¡¨æ–‡ä»¶ã€‚
        recursive: æ˜¯å¦é€’å½’æœç´¢ç›®å½•ï¼ˆboolï¼Œé»˜è®¤: Trueï¼‰ã€‚
        allowed_suffixes: å…è®¸çš„æ–‡ä»¶åç¼€åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤åŒ…å«å¸¸è§å›¾åƒæ ¼å¼ï¼‰ã€‚
        
    è¿”å›:
        list: æ’åºåçš„å›¾åƒç»å¯¹è·¯å¾„åˆ—è¡¨ï¼ˆstrï¼‰ã€‚
    """
    if allowed_suffixes is None:
        allowed_suffixes = [".jpg", ".jpeg", ".png", ".bmp", ".gif", ".webp"]
    input_path = Path(input_path).expanduser()
    if not input_path.exists():
        raise FileNotFoundError("è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {}".format(input_path))
    if input_path.is_file():
        suffix = input_path.suffix.lower()
        if suffix in allowed_suffixes:
            resolved = str(input_path.resolve())
            LOGGER.debug("æ”¶é›†å•å¼ å›¾åƒ: %s", resolved)
            return [resolved]
        if suffix in [".txt", ".csv", ".tsv"]:
            paths = []
            for line in input_path.read_text(encoding="utf-8").splitlines():
                item = line.strip()
                if not item:
                    continue
                if suffix == ".csv":
                    item = item.split(",")[0].strip()
                elif suffix == ".tsv":
                    item = item.split("\t")[0].strip()
                paths.append(item)
            if not paths:
                raise ValueError("åˆ—è¡¨æ–‡ä»¶æœªåŒ…å«æœ‰æ•ˆçš„å›¾åƒè·¯å¾„: {}".format(input_path))
            gathered = []
            for path in paths:
                p = Path(path).expanduser()
                if p.exists() and p.suffix.lower() in allowed_suffixes:
                    gathered.append(str(p.resolve()))
            if not gathered:
                raise ValueError("æœªåœ¨åˆ—è¡¨æ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆå›¾åƒ: {}".format(input_path))
            gathered = sorted(gathered)
            LOGGER.info("ä»åˆ—è¡¨åŠ è½½ %d å¼ å›¾åƒ: %s", len(gathered), input_path)
            return gathered
        raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {}".format(input_path.suffix))
    pattern = "**/*" if recursive else "*"
    files = []
    for file_path in input_path.glob(pattern):
        if file_path.is_file() and file_path.suffix.lower() in allowed_suffixes:
            files.append(str(file_path.resolve()))
    if not files:
        raise ValueError("æœªåœ¨ç›®å½•ä¸­æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å›¾åƒæ–‡ä»¶: {}".format(input_path))
    files = sorted(files)
    LOGGER.info("ä»ç›®å½•æ”¶é›† %d å¼ å›¾åƒ: %s", len(files), input_path)
    return files


def load_checkpoint(checkpoint_path, device=None):
    """åŠ è½½è®­ç»ƒä¿å­˜çš„æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚
    
    å‚æ•°:
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ï¼ˆstr æˆ– Pathï¼‰ã€‚
        device: ç›®æ ‡è®¾å¤‡æ ‡è¯†ï¼ˆstrï¼Œå¯é€‰ï¼‰ã€‚è‹¥ä¸º Noneï¼Œå°†è‡ªåŠ¨æ¨æ–­ã€‚
        
    è¿”å›:
        dict: åŒ…å« state_dictã€configã€metrics ç­‰å­—æ®µçš„æ£€æŸ¥ç‚¹å­—å…¸ã€‚
    """
    checkpoint_path = Path(checkpoint_path).expanduser()
    if not checkpoint_path.exists():
        raise FileNotFoundError("æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶: {}".format(checkpoint_path))
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    map_location = torch.device(device)
    LOGGER.info("åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹: %s", checkpoint_path)
    payload = torch.load(str(checkpoint_path), map_location=map_location)
    if not isinstance(payload, dict):
        raise RuntimeError("æ£€æŸ¥ç‚¹æ ¼å¼æ— æ•ˆ: {}".format(checkpoint_path))
    return payload


def _build_model_from_config(config, arch=None):
    """æ ¹æ®é…ç½®æ„å»ºæ¨¡å‹å®ä¾‹ã€‚
    
    å‚æ•°:
        config: è®­ç»ƒæ—¶ä¿å­˜çš„é…ç½®å­—å…¸ã€‚
        arch: æ¨¡å‹æ¶æ„åç§°ï¼ˆstrï¼Œå¯é€‰ï¼‰ï¼Œé»˜è®¤è¯»å– config['model_version']ã€‚
        
    è¿”å›:
        torch.nn.Module: åŠ è½½å®Œæˆçš„æ¨¡å‹å®ä¾‹ï¼ˆå°šæœªè½½å…¥æƒé‡ï¼‰ã€‚
    """
    arch = arch or config.get("model_version")
    dropout = config.get("dropout", 0.0)
    if arch == "cnn_v1":
        return create_CatDogCNNv1(num_classes=1, in_channels=3, dropout_p=dropout)
    if arch == "cnn_v2":
        return create_CatDogCNNv2(num_classes=1, in_channels=3, dropout_p=dropout)
    if arch in ["resnet18", "resnet34", "resnet50"]:
        return PretrainedResNet(
            model_name=arch,
            num_classes=1,
            pretrained=False,
            freeze_backbone=False,
            dropout_p=dropout,
        )
    raise ValueError("ä¸æ”¯æŒçš„æ¨¡å‹æ¶æ„: {}".format(arch))


def prepare_model(checkpoint_path, device=None, arch=None):
    """è½½å…¥æ¨¡å‹æ£€æŸ¥ç‚¹å¹¶å‡†å¤‡å¥½ç”¨äºæ¨ç†çš„æ¨¡å‹ã€‚
    
    å‚æ•°:
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ã€‚
        device: ç›®æ ‡è®¾å¤‡æ ‡è¯†ï¼ˆstrï¼Œå¯é€‰ï¼‰ï¼Œé»˜è®¤è‡ªåŠ¨é€‰æ‹©ã€‚
        arch: æ¨¡å‹æ¶æ„åç§°ï¼ˆstrï¼Œå¯é€‰ï¼‰ï¼Œç”¨äºè¦†ç›–æ£€æŸ¥ç‚¹é…ç½®ã€‚
        
    è¿”å›:
        tuple: (model, config) æ¨¡å‹å®ä¾‹ä¸é…ç½®å­—å…¸ã€‚
    
    ç¤ºä¾‹:
        >>> model, cfg = prepare_model("runs/torch_cnn/best.pt")
        >>> model.eval()
        PretrainedResNet(...)
    """
    payload = load_checkpoint(checkpoint_path, device=device)
    config = payload.get("config", {})
    model = _build_model_from_config(config, arch=arch)
    model.load_state_dict(payload["state_dict"])
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    model.eval()
    LOGGER.info("æ¨¡å‹å·²åŠ è½½åˆ°è®¾å¤‡: %s", device)
    return model, config


class _ImageListDataset(Dataset):
    """åŸºäºæ–‡ä»¶è·¯å¾„åˆ—è¡¨çš„ç®€å•æ¨ç†æ•°æ®é›†ã€‚"""

    def __init__(self, image_paths, transform):
        self.image_paths = image_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, index):
        image_path = self.image_paths[index]
        with Image.open(image_path) as image:
            image = image.convert("RGB")
            tensor = self.transform(image)
        return tensor, image_path


def run_inference(model, image_paths, transform, device, batch_size=32, threshold=0.5, show_progress=True, logger=None):
    """æ‰§è¡Œæ‰¹é‡æ¨ç†å¹¶è¿”å›ç»“æœåˆ—è¡¨ã€‚
    
    å‚æ•°:
        model: å·²åŠ è½½æƒé‡å¹¶åˆ‡æ¢åˆ° eval æ¨¡å¼çš„ PyTorch æ¨¡å‹ã€‚
        image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨ï¼ˆlistï¼‰ã€‚
        transform: å›¾åƒé¢„å¤„ç†å˜æ¢ï¼ˆtorchvision.transforms.Composeï¼‰ã€‚
        device: æ¨ç†è®¾å¤‡ï¼ˆstr æˆ– torch.deviceï¼‰ã€‚
        batch_size: æ¨ç†æ‰¹æ¬¡å¤§å°ï¼ˆintï¼Œé»˜è®¤: 32ï¼‰ã€‚
        threshold: å°†æ¦‚ç‡è½¬æ¢ä¸ºç±»åˆ«æ ‡ç­¾çš„é˜ˆå€¼ï¼ˆfloatï¼Œé»˜è®¤: 0.5ï¼‰ã€‚
        show_progress: æ˜¯å¦æ˜¾ç¤º tqdm è¿›åº¦æ¡ï¼ˆboolï¼Œé»˜è®¤: Trueï¼‰ã€‚
        logger: æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰ã€‚è‹¥æœªæä¾›ï¼Œä½¿ç”¨æ¨¡å—æ—¥å¿—ã€‚
        
    è¿”å›:
        list: ç»“æœå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« pathã€probã€labelã€label_nameã€‚
    """
    dataset = _ImageListDataset(image_paths, transform)
    loader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=torch.cuda.is_available(),
    )
    device = torch.device(device)
    results = []
    sigmoid = torch.nn.Sigmoid()
    tqdm_bar = None
    iterator = loader
    logger = logger or LOGGER
    logger.info("å¼€å§‹æ¨ç†ï¼Œæ€»è®¡ %d å¼ å›¾åƒï¼Œæ‰¹æ¬¡å¤§å° %d", len(image_paths), batch_size)
    if show_progress:
        tqdm_bar = tqdm(
            loader,
            desc="ğŸ”® æ¨ç†ä¸­",
            unit="batch",
            ncols=100,
            leave=False,
        )
        iterator = tqdm_bar
    for batch, batch_paths in iterator:
        batch = batch.to(device, non_blocking=True)
        with torch.no_grad():
            logits = model(batch)
            probs = sigmoid(logits.view(-1))
        for prob, path in zip(probs.tolist(), batch_paths):
            label = 1 if prob >= threshold else 0
            label_name = CLASS_NAMES[label]
            results.append(
                {
                    "path": path,
                    "prob": prob,
                    "label": label,
                    "label_name": label_name,
                }
            )
    if tqdm_bar is not None:
        tqdm_bar.close()
    logger.info("æ¨ç†å®Œæˆï¼Œç”Ÿæˆ %d æ¡ç»“æœã€‚", len(results))
    return results


def summarize_predictions(results):
    """æ±‡æ€»é¢„æµ‹ç»“æœï¼Œç»Ÿè®¡å„ç±»åˆ«æ•°é‡ä¸å¹³å‡ç½®ä¿¡åº¦ã€‚
    
    å‚æ•°:
        results: æ¨ç†ç»“æœåˆ—è¡¨ï¼Œç”± run_inference è¿”å›ã€‚
        
    è¿”å›:
        dict: åŒ…å«æ€»æ•°ã€å„ç±»åˆ«è®¡æ•°ã€å¹³å‡ç½®ä¿¡åº¦ç­‰ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ã€‚
    """
    if not results:
        return {
            "total": 0,
            "cats": {"count": 0, "avg_prob": 0.0},
            "dogs": {"count": 0, "avg_prob": 0.0},
        }
    total = len(results)
    accum = {
        "cats": {"count": 0, "prob_sum": 0.0},
        "dogs": {"count": 0, "prob_sum": 0.0},
    }
    for item in results:
        label_name = item["label_name"]
        prob = item["prob"]
        if label_name == "cats":
            accum["cats"]["count"] += 1
            accum["cats"]["prob_sum"] += 1.0 - prob
        else:
            accum["dogs"]["count"] += 1
            accum["dogs"]["prob_sum"] += prob
    cats_avg = accum["cats"]["prob_sum"] / max(accum["cats"]["count"], 1)
    dogs_avg = accum["dogs"]["prob_sum"] / max(accum["dogs"]["count"], 1)
    return {
        "total": total,
        "cats": {
            "count": accum["cats"]["count"],
            "avg_prob": cats_avg,
        },
        "dogs": {
            "count": accum["dogs"]["count"],
            "avg_prob": dogs_avg,
        },
    }


